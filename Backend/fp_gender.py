# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wQPAJHnDe8VDuRkBn2ZlC1aDKyqkq4au
"""

import tensorflow as tf
tf.test.gpu_device_name()

import zipfile

!unzip /content/drive/MyDrive/archive.zip

import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf

import os
import cv2

import matplotlib.pyplot as plt

def extract_label(img_path,underscore_flag ):
    filename, _ = os.path.splitext(os.path.basename(img_path))

    subject_id, etc = filename.split('__')

    if underscore_flag:
      gender, _, _, _, _ = etc.split('_')
    else:
      gender, _, _, _ = etc.split('_')

    gender = 0 if gender == 'M' else 1

    return np.array([gender], dtype=np.uint16)

def loading_data(path,boolean):
    data = []
    for img in os.listdir(path):
            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)
            img_resize = cv2.resize(img_array, (96,96))
            label = extract_label(os.path.join(path, img),boolean)

            data.append([label[0], img_resize ])

    return data

Real_path='/content/SOCOFing/Real'
Altered_easy_path='/content/SOCOFing/Altered/Altered-Easy'
Altered_medium_path='/content/SOCOFing/Altered/Altered-Medium'
Altered_hard_path='/content/SOCOFing/Altered/Altered-Hard'

Easy_data = loading_data(Altered_easy_path,True)

Med_data=loading_data(Altered_medium_path,True)

Hard_data=loading_data(Altered_hard_path,True)

#Real_data=loading_data(Real_path,False)

img, labels = [], []
for label, feature in Easy_data:
    labels.append(label)
    img.append(feature)

for label, feature in Med_data:
    labels.append(label)
    img.append(feature)

for label, feature in Hard_data:
    labels.append(label)
    img.append(feature)

#for label, feature in Real_data:
 #   labels.append(label)
 #   img.append(feature)

train_data = np.array(img).reshape(-1, 96, 96, 1)
train_data = train_data / 255.0

print(train_data.ndim)
print(train_data.shape)

from keras.utils import to_categorical
train_labels = to_categorical(labels, num_classes = 2)

labels = np.array(labels)

plt.imshow(train_data[400],cmap='gray')
plt.axis('off')
plt.show()

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout
from tensorflow.keras import layers
from tensorflow.keras import optimizers

model = Sequential()
model.add(Conv2D(32, 3, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.01), kernel_initializer='he_uniform', input_shape=(96, 96, 1)))
model.add(MaxPooling2D(2))
model.add(Conv2D(32, 3, padding='same', kernel_initializer='he_uniform', activation=tf.keras.layers.LeakyReLU(alpha=0.01)))
model.add(MaxPooling2D(2))
model.add(Flatten())
model.add(Dense(128, kernel_initializer='he_uniform', activation=tf.keras.layers.LeakyReLU(alpha=0.01)))
model.add(Dense(64, kernel_initializer='he_uniform', activation=tf.keras.layers.LeakyReLU(alpha=0.01)))
model.add(Dense(32, kernel_initializer='he_uniform', activation=tf.keras.layers.LeakyReLU(alpha=0.01)))
model.add(Dense(16, kernel_initializer='he_uniform', activation=tf.keras.layers.LeakyReLU(alpha=0.01)))
model.add(Dense(8, kernel_initializer='he_uniform', activation=tf.keras.layers.LeakyReLU(alpha=0.01)))
model.add(Dense(4, kernel_initializer='he_uniform', activation=tf.keras.layers.LeakyReLU(alpha=0.01)))
model.add(Dense(2, kernel_initializer='he_uniform', activation=tf.keras.layers.LeakyReLU(alpha=0.01)))
model.add(Dense(1, activation='sigmoid'))

model.summary()

model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])

training_stop= tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)

model_fitting= model.fit(train_data, labels, batch_size = 64, epochs = 48,
                 validation_split = 0.2, callbacks = [training_stop], verbose = 1)

plt.plot(model_fitting.history['accuracy'])
plt.plot(model_fitting.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(model_fitting.history['loss'])
plt.plot(model_fitting.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

test_data = loading_data(Real_path,False)

x_test,y_test= [], []
for label, feature in test_data:
    y_test.append(label)
    x_test.append(feature)

x_test = np.array(x_test).reshape(-1, 96, 96, 1)
y_test = np.array(y_test)

model.evaluate(x_test,y_test)

from sklearn.metrics import confusion_matrix

plt.figure(figsize=(15, 5))

preds = model.predict(x_test)
preds = (preds >= 0.5).astype(np.int32)
cm = confusion_matrix(y_test, preds)
df_cm = pd.DataFrame(cm, index=['Male', 'Female'], columns=['Male', 'Female'])
plt.subplot(121)
plt.title("Confusion matrix for my model\n")
sns.heatmap(df_cm, annot=True, fmt="d", cmap="YlGnBu")
plt.ylabel("Predicted")
plt.xlabel("Actual")

print(len(y_test==1))

model.save('GenderFP.keras')

for i in range(20):
    print('True: ',y_test[i])
    print('predicted: ',model.predict(np.expand_dims(x_test[i],0))[0])
    print()
    plt.imshow(x_test[i],'gray')
    plt.show()

from sklearn.metrics import precision_score, recall_score, f1_score

y_test_predictions=model.predict(x_test)
y_test_predictions = (y_test_predictions >= 0.5).astype(np.int16)
print(y_test.dtype)
print(y_test_predictions.dtype)
precision = precision_score(y_test, y_test_predictions)
recall = recall_score(y_test, y_test_predictions)
f1score = f1_score(y_test, y_test_predictions)

print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1score:.2f}")

import joblib

joblib.dump(model, 'fp_model.joblib')